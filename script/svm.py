import getopt
import sys

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import classification_report, confusion_matrix
from joblib import dump, load
import pcap_parser as pp
import gather_characteristics as gc
import combine_csvs as cc
import numpy as np

from time import time, ctime


def train_data(model_filename, X, y, c=10, kern='linear', testsize=0.90):
    t0 = time()

    # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.98)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testsize)
    # clf = SVC(kernel="linear", C=0.1, verbose=False, probability=True, cache_size=6000)
    # clf = SVC(kernel="linear", C=1, verbose=False, probability=True, cache_size=6000)
    # clf = SVC(kernel="linear", C=10, verbose=False, probability=True, cache_size=6000)
    clf = SVC(degree=1, gamma='scale', kernel=kern, C=c, verbose=False, probability=True)
    clf.fit(X_train, y_train)
    t1 = time()
    print("Model filename: ", model_filename, '\n')
    print("Trainingpackets: ", len(X_train))
    print("Trainingtime: %0.3fs: " % (t1 - t0))

    y_pred = clf.predict(X_test)
    t2 = time()
    print("Testingpackets: ", len(X_test))
    print("Testingtime: %0.3fs: " % (t2 - t1))

    print(clf.get_params, '\n')
    print(confusion_matrix(y_test, y_pred), '\n')
    print(classification_report(y_test, y_pred), '\n')
    print("================================================================\n")
    dump(clf, model_filename)

    return clf

def test_classifier(model_filename, X, y):
    pass



def use_existing_classifier(model_filename, testfile):
    clf = load(model_filename)
    parsed = "../captures/nmap_sS/scanme_parsed.csv"
    processed = "../captures/nmap_sS/scanme_processed.csv"
    combined = "../captures/nmap_sS/scanme_nmap_sS_characteristics_fixed.csv_combined.csv"

    # pp.write_csv(pp.process_pcap(testfile), "nmap_sS", parsed)
    #
    # df = pd.read_csv(parsed)
    # characteristics = gc.chars_in_time_frame(df)
    # characteristics.to_csv(processed)
    #
    # cc.main([processed,combined])


    combined_list = pd.read_csv(combined)
    y = combined_list.pop("data_class")

    print(y)

    # print(type(combined_list.loc[2]))
    # print(combined_list.columns)
    input_pred = clf.predict_proba(combined_list)

    for prediction in input_pred:
        print(list(zip(clf.classes_, prediction)))

    input_pred = clf.predict(combined_list)

    unique, counts = np.unique(input_pred, return_counts=True)
    print(dict(zip(unique, counts)))
    print(clf.classes_)

    print(confusion_matrix(y, input_pred), '\n')
    print(classification_report(y, input_pred), '\n')


def main(argv):
    """ Main program """
    model_filename = "../captures/svc_model_other_fixed.joblib"
    testfile = ""
    trainfile = "../captures/combined/dirb_nmap_ssh_other_fixed.csv"
    train = False
    classify = False

    try:
        opts, args = getopt.getopt(argv, "c:t:", )
    except getopt.GetoptError:
        print
        'test.py -t <train_file> -c <classify_file> -m <model_filename>'
        sys.exit(2)
    for opt, arg in opts:
        if opt == '-t':
            train = True
            trainfile = arg
        elif opt == '-c':
            classify = True
            testfile = arg
        elif opt == '-m':
            model_filename = arg
    print(ctime())
    if train:
        print("Trian & test dataset filename: ", trainfile, '\n')
        X = pd.read_csv(trainfile)
        X = X.sample(frac=1).reset_index(drop=True)             # Shuffle the rows and reset indexes
        # print("Attributes used: ", X.columns, '\n')
        y = X.pop('data_class').values
        # for cc in [0.1, 1, 10]:
        #     print("C = ", cc)
        #     print("----------------------------------------------------------------------")
        #     for s in [0.99]:
        #         print("Testsize = ", s)
        #         print("------------------------------------------------------------")
        #         for i in [1,2,3,4,5]:
        #             print("NUMBER ", i)
        #             svclassifier = train_data(model_filename, X, y, kern='linear', c=cc, testsize=s)
        svclassifier = train_data(model_filename, X, y, kern='linear', c=1, testsize=0.99)


    if classify:
        use_existing_classifier(model_filename, testfile)

    return


if __name__ == "__main__":
    main(sys.argv[1:])

